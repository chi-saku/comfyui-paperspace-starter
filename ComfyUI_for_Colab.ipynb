{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ComfyUI for Google Colab - æ•™è‚²ç”¨å®Œå…¨ç‰ˆ\n",
        "\n",
        "**ğŸ¨ ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§ComfyUIãŒèµ·å‹•ã™ã‚‹é­”æ³•ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯**\n",
        "\n",
        "## ğŸš€ ä½¿ç”¨æ–¹æ³•\n",
        "1. ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã€â†’ã€Œãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ã€â†’ã€ŒT4 GPUã€ã‚’é¸æŠ\n",
        "2. ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œï¼ˆç´„10-15åˆ†ï¼‰\n",
        "3. è¡¨ç¤ºã•ã‚Œã‚‹ `https://xxxxx.trycloudflare.com` ã‚’ã‚¯ãƒªãƒƒã‚¯\n",
        "4. ComfyUIã§ç”»åƒç”Ÿæˆé–‹å§‹ï¼\n",
        "\n",
        "## ğŸ“ ä¿å­˜å…ˆ\n",
        "ç”Ÿæˆç”»åƒã¯ `/content/drive/MyDrive/ComfyUI/output/` ã«æ°¸ç¶šä¿å­˜ã•ã‚Œã¾ã™ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os, sys, time, re, socket, subprocess, threading\n",
        "from pathlib import Path\n",
        "\n",
        "print('ğŸ¨ ComfyUI Google Colab æ•™è‚²ç‰ˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—')\n",
        "print('=' * 50)\n",
        "\n",
        "# Google Colabå°‚ç”¨è¨­å®š\n",
        "COMFY_DIR = Path('/content/drive/MyDrive/ComfyUI')\n",
        "MGR_DIR = COMFY_DIR / 'custom_nodes' / 'ComfyUI-Manager'\n",
        "CHECKPOINT_DIR = COMFY_DIR / 'models' / 'checkpoints'\n",
        "OUTPUT_DIR = COMFY_DIR / 'output'\n",
        "PORT = 8123\n",
        "\n",
        "def run_cmd(cmd, check=True, shell=False, cwd=None, quiet=False):\n",
        "    if not quiet: print('$ ' + (cmd if isinstance(cmd, str) else ' '.join(cmd)))\n",
        "    return subprocess.run(cmd, check=check, shell=shell, cwd=cwd, capture_output=quiet)\n",
        "\n",
        "print('\\nğŸ“ Step-1: Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¾ã™...')\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "print('\\nğŸ§¹ Step-2: ç’°å¢ƒã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¾ã™...')\n",
        "subprocess.run('pkill -f cloudflared || true', shell=True)\n",
        "subprocess.run('pkill -f \"python.*main.py\" || true', shell=True)\n",
        "subprocess.run(f'fuser -k {PORT}/tcp || true', shell=True)\n",
        "time.sleep(2)\n",
        "\n",
        "print('\\nğŸ“¥ Step-3: ComfyUIã¨Managerã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™...')\n",
        "# å¿…è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
        "for directory in [CHECKPOINT_DIR, OUTPUT_DIR, COMFY_DIR / 'input']:\n",
        "    directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ComfyUIæœ¬ä½“\n",
        "if COMFY_DIR.exists() and (COMFY_DIR / 'main.py').exists():\n",
        "    try:\n",
        "        run_cmd(['git', 'pull', '--rebase', '--autostash'], cwd=str(COMFY_DIR), check=False, quiet=True)\n",
        "        print('ğŸ”„ æ—¢å­˜ComfyUIã‚’æ›´æ–°ã—ã¾ã—ãŸ')\n",
        "    except:\n",
        "        print('ğŸ”„ æ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™')\n",
        "else:\n",
        "    if COMFY_DIR.exists():\n",
        "        run_cmd(['rm', '-rf', str(COMFY_DIR)], check=False, quiet=True)\n",
        "    print('ğŸ“¥ ComfyUIã‚’æ–°è¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...')\n",
        "    run_cmd(['git', 'clone', '--depth=1', 'https://github.com/comfyanonymous/ComfyUI.git', str(COMFY_DIR)])\n",
        "\n",
        "# ComfyUI-Manager\n",
        "if not MGR_DIR.exists():\n",
        "    print('ğŸ“¥ ComfyUI-Managerè¿½åŠ ä¸­...')\n",
        "    run_cmd(['git', 'clone', '--depth=1', 'https://github.com/ltdrdata/ComfyUI-Manager.git', str(MGR_DIR)])\n",
        "\n",
        "print('\\nğŸ“¦ Step-4: ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™...')\n",
        "run_cmd([sys.executable, '-m', 'pip', 'install', '-q', '--upgrade', 'pip', 'setuptools', 'wheel'], quiet=True)\n",
        "\n",
        "# PyTorchç¢ºèª\n",
        "try:\n",
        "    import torch\n",
        "    torch_ver = torch.__version__.split('+')[0]\n",
        "    print(f'âœ… PyTorch {torch_ver} æ¤œå‡ºæ¸ˆã¿')\n",
        "except ImportError:\n",
        "    print('ğŸ“¥ PyTorchã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...')\n",
        "    run_cmd([sys.executable, '-m', 'pip', 'install', '-q', 'torch', 'torchvision', 'torchaudio', '--index-url', 'https://download.pytorch.org/whl/cu121'], quiet=True)\n",
        "    import torch\n",
        "    torch_ver = torch.__version__.split('+')[0]\n",
        "\n",
        "# ComfyUIè¦ä»¶\n",
        "req_file = COMFY_DIR / 'requirements.txt'\n",
        "if req_file.exists():\n",
        "    print('ğŸ”§ ComfyUIä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...')\n",
        "    run_cmd([sys.executable, '-m', 'pip', 'install', '-q', '-r', str(req_file), '--prefer-binary'], check=False, quiet=True)\n",
        "\n",
        "# Managerè¦ä»¶ï¼ˆã‚¨ãƒ©ãƒ¼è¨±å®¹ï¼‰\n",
        "mgr_req = MGR_DIR / 'requirements.txt'\n",
        "if mgr_req.exists():\n",
        "    run_cmd([sys.executable, '-m', 'pip', 'install', '-q', '-r', str(mgr_req)], check=False, quiet=True)\n",
        "\n",
        "# xformersè‡ªå‹•æ•´åˆ\n",
        "try:\n",
        "    major_minor = '.'.join(torch_ver.split('.')[:2])\n",
        "    xformers_map = {'2.0': '0.0.20', '2.1': '0.0.22.post7', '2.2': '0.0.25', \n",
        "                   '2.3': '0.0.27', '2.4': '0.0.28.post1', '2.5': '0.0.28.post1'}\n",
        "    xformers_ver = xformers_map.get(major_minor, '0.0.28.post1')\n",
        "    print(f'ğŸ”§ xformers {xformers_ver} æ•´åˆä¸­...')\n",
        "    run_cmd([sys.executable, '-m', 'pip', 'install', '-q', f'xformers=={xformers_ver}'], check=False, quiet=True)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "print('\\nğŸ¤– Step-5: åŸºæœ¬ãƒ¢ãƒ‡ãƒ«æº–å‚™ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰...')\n",
        "model_path = CHECKPOINT_DIR / 'v1-5-pruned-emaonly.safetensors'\n",
        "if not model_path.exists():\n",
        "    model_url = 'https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.safetensors'\n",
        "    HF_TOKEN = os.environ.get('HUGGINGFACE_TOKEN', '').strip()\n",
        "    \n",
        "    print('ğŸ“¥ SD1.5ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰è©¦è¡Œä¸­...')\n",
        "    download_success = False\n",
        "    \n",
        "    if HF_TOKEN:\n",
        "        try:\n",
        "            cmd = f'wget -q --timeout=300 -O \"{model_path}\" --header=\"Authorization: Bearer {HF_TOKEN}\" \"{model_url}\"'\n",
        "            result = subprocess.run(cmd, shell=True, timeout=600)\n",
        "            if result.returncode == 0 and model_path.exists():\n",
        "                download_success = True\n",
        "                print('âœ… èªè¨¼ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†')\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    if not download_success:\n",
        "        try:\n",
        "            result = subprocess.run(['wget', '--timeout=300', '-c', model_url, '-O', str(model_path)], timeout=600, check=False)\n",
        "            if result.returncode == 0 and model_path.exists():\n",
        "                download_success = True\n",
        "                print('âœ… ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†')\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    if not download_success:\n",
        "        print('ğŸ’¡ ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—ï¼ˆå¾Œã§Managerã‹ã‚‰è¿½åŠ å¯èƒ½ï¼‰')\n",
        "else:\n",
        "    print('âœ… åŸºæœ¬ãƒ¢ãƒ‡ãƒ«å­˜åœ¨ç¢ºèª')\n",
        "\n",
        "print('\\nğŸŒ Step-6: cloudflaredã‚’æº–å‚™ã—ã¾ã™...')\n",
        "if not Path('/usr/local/bin/cloudflared').exists():\n",
        "    run_cmd(['wget', '-q', 'https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64', '-O', '/usr/local/bin/cloudflared'], quiet=True)\n",
        "    run_cmd(['chmod', '+x', '/usr/local/bin/cloudflared'], quiet=True)\n",
        "\n",
        "def wait_for_port(host, port, timeout=180):\n",
        "    print(f'ğŸ” ComfyUIèµ·å‹•ã‚’å¾…æ©Ÿä¸­...')\n",
        "    start = time.time()\n",
        "    while time.time() - start < timeout:\n",
        "        try:\n",
        "            with socket.create_connection((host, port), timeout=2):\n",
        "                print('ğŸ‰ ComfyUIãŒèµ·å‹•ã—ã¾ã—ãŸï¼')\n",
        "                return True\n",
        "        except:\n",
        "            time.sleep(2)\n",
        "    print('âŒ ComfyUIèµ·å‹•ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ')\n",
        "    return False\n",
        "\n",
        "def start_comfyui():\n",
        "    print('\\nğŸš€ ComfyUIã‚’èµ·å‹•ã—ã¾ã™...')\n",
        "    env = os.environ.copy()\n",
        "    env['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "    \n",
        "    cmd = [\n",
        "        sys.executable, 'main.py',\n",
        "        '--listen=0.0.0.0',\n",
        "        f'--port={PORT}',\n",
        "        f'--output-directory={OUTPUT_DIR}',\n",
        "        '--disable-cuda-malloc',\n",
        "        '--normalvram'\n",
        "    ]\n",
        "    \n",
        "    proc = subprocess.Popen(cmd, cwd=str(COMFY_DIR), env=env,\n",
        "                           stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
        "                           text=True, bufsize=1)\n",
        "    \n",
        "    startup_keywords = ['Uvicorn running', 'Application startup complete']\n",
        "    for line in iter(proc.stdout.readline, ''):\n",
        "        if not line: break\n",
        "        print(f'[ComfyUI] {line.strip()}')\n",
        "        if any(keyword in line for keyword in startup_keywords):\n",
        "            print('ğŸŠ ComfyUIå®Œå…¨èµ·å‹•å®Œäº†ï¼')\n",
        "            break\n",
        "    return proc\n",
        "\n",
        "def start_cloudflared():\n",
        "    print('\\nğŸŒ å¤–éƒ¨ã‚¢ã‚¯ã‚»ã‚¹ç”¨ãƒˆãƒ³ãƒãƒ«ã‚’ä½œæˆä¸­...')\n",
        "    cmd = ['cloudflared', 'tunnel', f'--url=http://0.0.0.0:{PORT}',\n",
        "           '--protocol', 'http2', '--no-autoupdate', '--loglevel', 'warn']\n",
        "    \n",
        "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
        "                           text=True, bufsize=1)\n",
        "    \n",
        "    for line in iter(proc.stdout.readline, ''):\n",
        "        if not line: break\n",
        "        print(f'[cloudflared] {line.strip()}')\n",
        "        \n",
        "        url_match = re.search(r'https://[a-z0-9-]+\\\\.trycloudflare\\\\.com', line)\n",
        "        if url_match:\n",
        "            public_url = url_match.group(0)\n",
        "            print('\\n' + 'ğŸ‰' * 20)\n",
        "            print(f'âœ¨ é­”æ³•ã®URL: {public_url}')\n",
        "            print('ğŸ“± ä¸Šè¨˜URLã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ComfyUIã«ã‚¢ã‚¯ã‚»ã‚¹ï¼')\n",
        "            print('ğŸ‰' * 20)\n",
        "            break\n",
        "    return proc\n",
        "\n",
        "print('\\n' + '=' * 50)\n",
        "print('ğŸ¯ ComfyUIèµ·å‹•ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é–‹å§‹')\n",
        "print('=' * 50)\n",
        "\n",
        "try:\n",
        "    # ComfyUIã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§èµ·å‹•\n",
        "    comfy_thread = threading.Thread(target=start_comfyui, daemon=True)\n",
        "    comfy_thread.start()\n",
        "    \n",
        "    # ãƒãƒ¼ãƒˆé–‹é€šå¾…æ©Ÿ\n",
        "    if wait_for_port('127.0.0.1', PORT):\n",
        "        # cloudflaredãƒˆãƒ³ãƒãƒ«ä½œæˆ\n",
        "        cf_proc = start_cloudflared()\n",
        "        \n",
        "        print('\\nğŸŠ ComfyUIæ•™è‚²ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼')\n",
        "        print(f'ğŸ“ ç”Ÿæˆç”»åƒä¿å­˜å…ˆ: {OUTPUT_DIR}')\n",
        "        \n",
        "        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¶­æŒ\n",
        "        try:\n",
        "            while True:\n",
        "                time.sleep(30)\n",
        "                if cf_proc.poll() is not None:\n",
        "                    print('âš ï¸ ãƒˆãƒ³ãƒãƒ«æ¥ç¶šãŒåˆ‡æ–­ã•ã‚Œã¾ã—ãŸ')\n",
        "                    break\n",
        "        except KeyboardInterrupt:\n",
        "            print('\\nğŸ›‘ ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†è¦æ±‚ã‚’å—ã‘ã¾ã—ãŸ')\n",
        "    else:\n",
        "        print('âŒ ComfyUIèµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f'âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}')\n",
        "    print('ğŸ’¡ ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
